{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import polars as pl \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_header(file_path, skip=0):\n",
    "    \"\"\"Attempt to read just the header of an Excel file with varying skip rows.\"\"\"\n",
    "    try:\n",
    "        col_list = pd.read_excel(file_path, nrows=0, skiprows=skip).columns\n",
    "        return col_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading header from {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def find_unique_schemas(directory):\n",
    "    \"\"\"Finds and returns unique schemas from Excel files in a given directory.\"\"\"\n",
    "    schemas = {}\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.xlsx'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                columns = read_excel_header(file_path)\n",
    "                num_columns = len(columns)\n",
    "                skip_r=1\n",
    "                while num_columns <3:\n",
    "                    columns = read_excel_header(file_path, skip=skip_r)\n",
    "                    num_columns = len(columns)\n",
    "                    skip_r+=1\n",
    "                schema_key = tuple(columns)  # Use tuple of columns as a unique schema key\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to open file {filename}: {e}\")\n",
    "\n",
    "            if schema_key not in schemas:\n",
    "                schemas[schema_key] = []\n",
    "            schemas[schema_key].append(filename)\n",
    "    return schemas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:07<00:00,  9.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "directory = 'downloaded_files'\n",
    "unique_schemas = find_unique_schemas(directory)\n",
    "\n",
    "# Printing unique schemas and the files that match them\n",
    "#for schema, files in unique_schemas.items():\n",
    "#    print(f\"Schema: {schema} \\nFiles: {files}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort elements within each tuple and deduplicate\n",
    "sorted_unique_schemas = set(tuple(sorted(schema)) for schema in unique_schemas.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = list(unique_schemas.values())[0]\n",
    "schema2 = list(unique_schemas.values())[1]\n",
    "schema3 = list(unique_schemas.values())[2]\n",
    "schema4 = list(unique_schemas.values())[3]\n",
    "schema5 = list(unique_schemas.values())[4]\n",
    "schema6 = list(unique_schemas.values())[5]\n",
    "schema7 = list(unique_schemas.values())[6]\n",
    "schema8 = list(unique_schemas.values())[7]\n",
    "schema9 = list(unique_schemas.values())[8]\n",
    "schema10 = list(unique_schemas.values())[9]\n",
    "schema11 = list(unique_schemas.values())[10]\n",
    "schema12 = list(unique_schemas.values())[11]\n",
    "schema13 = list(unique_schemas.values())[12]\n",
    "schema14 = list(unique_schemas.values())[13]\n",
    "schema15 = list(unique_schemas.values())[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema definition moved outside of the loop\n",
    "final_schema_columns = ['Fecha', 'Año', 'Mes', 'Sigla Empresa', 'Nombre Empresa',\n",
    "                        'Origen', 'Destino', 'Apto_Origen', 'Apto_Destino',\n",
    "                        'Pasajeros', 'Trafico', 'TipoVuelo', 'Ciudad Origen', \n",
    "                        'Ciudad Destino', 'Pais Origen', 'Pais Destino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/68 [00:00<?, ?it/s]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 21%|██        | 14/68 [00:25<03:57,  4.39s/it]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 28%|██▊       | 19/68 [00:30<01:12,  1.48s/it]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 41%|████      | 28/68 [00:43<00:41,  1.04s/it]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 47%|████▋     | 32/68 [00:47<00:35,  1.02it/s]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 99%|█████████▊| 67/68 [01:55<00:04,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Origen-Destino Mes 2014.xlsx: \"['Fecha'] not in index\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [02:05<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Origen-Destino Mes 2015.xlsx: \"['Fecha'] not in index\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Processing loop\n",
    "df_list = []\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        skip_r = 0\n",
    "        columns = read_excel_header(file_path, skip=skip_r)\n",
    "        while len(columns) < 3 and skip_r < 10:\n",
    "            columns = read_excel_header(file_path, skip=skip_r)\n",
    "            skip_r += 1\n",
    "\n",
    "        try:\n",
    "            tmp = pd.read_excel(file_path, skiprows=skip_r, dtype=\"str\")\n",
    "            if (filename in schema1) | (filename in schema5)  | (filename in schema6) | (filename in schema11):\n",
    "                tmp[\"Año\"] = tmp['Fecha'].str.slice(start=0, stop=4)\n",
    "                tmp[\"Mes\"] = tmp['Fecha'].str.slice(start=5, stop=7)\n",
    "                tmp = tmp[final_schema_columns]\n",
    "                pl_tmp = pl.from_pandas(tmp)\n",
    "                df_list.append(pl_tmp)\n",
    "            elif (filename in schema2) | (filename in schema3) | (filename in schema4) | (filename in schema8) | (filename in schema12) :\n",
    "                tmp = tmp.rename(columns={\"Nombre\":'Nombre Empresa',\"Número de Mes\":\"Mes\",\"MES\":\"Mes\",\n",
    "                                          \"Nombre.1\":'Apto_Origen',\"Nombre.2\":'Apto_Destino',\n",
    "                                          \"Tráfico (N/I)\":'Trafico',\"Tipo Vuelo\":'TipoVuelo',\n",
    "                                          \"Apto Origen\":'Apto_Origen',\"Apto Destino\":'Apto_Destino',\n",
    "                                          \"Fecha Visual\":\"Fecha\", \"Tráfico\":\"Trafico\", \"AÑO\":\"Año\"}) \n",
    "                tmp = tmp[final_schema_columns]\n",
    "                pl_tmp = pl.from_pandas(tmp)\n",
    "                df_list.append(pl_tmp)\n",
    "            elif filename in schema7:\n",
    "                tmp = pd.read_excel(file_path, skiprows=1, dtype=\"str\", sheet_name=1)\n",
    "                tmp = tmp.rename(columns={\"Nombre\":'Nombre Empresa',\"Número de Mes\":\"Mes\",\"MES\":\"Mes\",\n",
    "                                          \"Nombre.1\":'Apto_Origen',\"Nombre.2\":'Apto_Destino',\n",
    "                                          \"Tráfico (N/I)\":'Trafico',\"Tipo Vuelo\":'TipoVuelo',\n",
    "                                          \"Apto Origen\":'Apto_Origen',\"Apto Destino\":'Apto_Destino',\n",
    "                                          \"Fecha Visual\":\"Fecha\", \"Tráfico\":\"Trafico\", \"AÑO\":\"Año\"}) \n",
    "                tmp = tmp[final_schema_columns]\n",
    "                pl_tmp = pl.from_pandas(tmp)\n",
    "                df_list.append(pl_tmp)\n",
    "            else:\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process file {filename}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df = pl.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:06<00:00, 10.27it/s]\n",
      "  0%|          | 0/68 [00:00<?, ?it/s]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 21%|██        | 14/68 [00:26<04:07,  4.58s/it]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 28%|██▊       | 19/68 [00:31<01:20,  1.64s/it]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 34%|███▍      | 23/68 [00:40<01:21,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Base de Datos Origen - Destino Febrero 2023.xlsx: Worksheet index 1 is invalid, 1 worksheets found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 26/68 [00:42<00:45,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Base de Datos Origen - Destino Julio 2021.xlsx: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 28/68 [00:44<00:41,  1.04s/it]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 47%|████▋     | 32/68 [00:48<00:37,  1.05s/it]d:\\Proyectos\\air.traffic.trends-CO\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      " 59%|█████▉    | 40/68 [00:58<00:37,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Base de datos Origen - Destino Noviembre 2019.xlsx: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 53/68 [01:10<00:12,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Base de Datos Origen-Destino Agosto 2020.xlsx: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 57/68 [01:22<00:22,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Base de Datos Origen-Destino Julio 2020.xlsx: \n",
      "Failed to process file Base de Datos Origen-Destino Marzo 2020.xlsx: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 63/68 [01:24<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Base de Datos Origen-Destino Mayo 2020.xlsx: \n",
      "Failed to process file Base de Datos Origen-Destino Octubre 2020.xlsx: \n",
      "Failed to process file Base de Datos Origen-Destino Septiembre 2020.xlsx: \n",
      "Failed to process file Bases de Datos Origen-Destino Abril 2020.xlsx: \n",
      "Failed to process file Bases de Datos Origen-Destino Enero 2020.xlsx: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 65/68 [01:24<00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Bases de Datos Origen-Destino Febrero 2020.xlsx: \n",
      "Failed to process file Bases de Datos Origen-Destino Junio 2020.xlsx: \n",
      "Failed to process file Origen - Destino Mes 2016.xlsx: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 67/68 [01:24<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Origen-Destino Mes 2014.xlsx: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [01:25<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process file Origen-Destino Mes 2015.xlsx: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming the function definitions for read_excel_header and find_unique_schemas are unchanged\n",
    "\n",
    "# Usage example\n",
    "directory = 'downloaded_files'\n",
    "unique_schemas = find_unique_schemas(directory)\n",
    "\n",
    "# Mapping filenames to their schema index for better handling\n",
    "filename_to_schema_index = {filename: index for index, schemas in enumerate(unique_schemas.values()) for filename in schemas}\n",
    "\n",
    "# Schema mappings for renaming and adjustments\n",
    "schema_mappings = {\n",
    "    # Group similar handling schemas together\n",
    "    'group1': [0, 4, 5, 10],\n",
    "    'group2': [1, 2, 3, 7, 11],\n",
    "    'group3': [6]\n",
    "}\n",
    "\n",
    "# Processing loop\n",
    "df_list = []\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        skip_r = 0\n",
    "        columns = read_excel_header(file_path, skip=skip_r)\n",
    "        while len(columns) < 3 and skip_r < 10:\n",
    "            skip_r += 1\n",
    "            columns = read_excel_header(file_path, skip=skip_r)\n",
    "\n",
    "        schema_index = filename_to_schema_index.get(filename)\n",
    "        try:\n",
    "            group_key = next(key for key, indexes in schema_mappings.items() if schema_index in indexes)\n",
    "            tmp = pd.read_excel(file_path, skiprows=skip_r, dtype=\"str\")\n",
    "            \n",
    "            if group_key == 'group1':\n",
    "                tmp[\"Año\"] = tmp['Fecha'].str.slice(start=0, stop=4)\n",
    "                tmp[\"Mes\"] = tmp['Fecha'].str.slice(start=5, stop=7)\n",
    "            elif group_key == 'group2':\n",
    "                tmp = tmp.rename(columns={\"Nombre\": 'Nombre Empresa', \"Número de Mes\": \"Mes\", \"MES\": \"Mes\",\n",
    "                                          \"Nombre.1\": 'Apto_Origen', \"Nombre.2\": 'Apto_Destino',\n",
    "                                          \"Tráfico (N/I)\": 'Trafico', \"Tipo Vuelo\": 'TipoVuelo',\n",
    "                                          \"Apto Origen\": 'Apto_Origen', \"Apto Destino\": 'Apto_Destino',\n",
    "                                          \"Fecha Visual\": \"Fecha\", \"Tráfico\": \"Trafico\", \"AÑO\": \"Año\"})\n",
    "            elif group_key == 'group3':\n",
    "                tmp = pd.read_excel(file_path, skiprows=1, dtype=\"str\", sheet_name=\"DATOS\")\n",
    "            \n",
    "            tmp = tmp[final_schema_columns]\n",
    "            pl_tmp = pl.from_pandas(tmp)\n",
    "            df_list.append(pl_tmp)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process file {filename}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df = pl.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (556_413, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Fecha</th><th>Año</th><th>Mes</th><th>Sigla Empresa</th><th>Nombre Empresa</th><th>Origen</th><th>Destino</th><th>Apto_Origen</th><th>Apto_Destino</th><th>Pasajeros</th><th>Trafico</th><th>TipoVuelo</th><th>Ciudad Origen</th><th>Ciudad Destino</th><th>Pais Origen</th><th>Pais Destino</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2019-04-01 00:00:00&quot;</td><td>&quot;2019&quot;</td><td>&quot;04&quot;</td><td>&quot;AAL&quot;</td><td>&quot;AMERICAN&quot;</td><td>&quot;ABI&quot;</td><td>&quot;BOG&quot;</td><td>&quot;MUNICIPAL&quot;</td><td>&quot;BOGOTA - ELDORADO&quot;</td><td>&quot;1&quot;</td><td>&quot;I&quot;</td><td>&quot;R&quot;</td><td>&quot;TEXAS&quot;</td><td>&quot;BOGOTA&quot;</td><td>&quot;ESTADOS UNIDOS&quot;</td><td>&quot;COLOMBIA&quot;</td></tr><tr><td>&quot;2019-04-01 00:00:00&quot;</td><td>&quot;2019&quot;</td><td>&quot;04&quot;</td><td>&quot;AAL&quot;</td><td>&quot;AMERICAN&quot;</td><td>&quot;ABQ&quot;</td><td>&quot;BOG&quot;</td><td>&quot;ALBUQUERQUE INTL SUNPORT&quot;</td><td>&quot;BOGOTA - ELDORADO&quot;</td><td>&quot;37&quot;</td><td>&quot;I&quot;</td><td>&quot;R&quot;</td><td>&quot;NUEVO MEXICO&quot;</td><td>&quot;BOGOTA&quot;</td><td>&quot;ESTADOS UNIDOS&quot;</td><td>&quot;COLOMBIA&quot;</td></tr><tr><td>&quot;2019-04-01 00:00:00&quot;</td><td>&quot;2019&quot;</td><td>&quot;04&quot;</td><td>&quot;AAL&quot;</td><td>&quot;AMERICAN&quot;</td><td>&quot;ABZ&quot;</td><td>&quot;CLO&quot;</td><td>&quot;CYDE&quot;</td><td>&quot;CALI - ALFONSO BONILLA ARAGON&quot;</td><td>&quot;1&quot;</td><td>&quot;I&quot;</td><td>&quot;R&quot;</td><td>&quot;ABENDEEN&quot;</td><td>&quot;CALI&quot;</td><td>&quot;INGLATERRA&quot;</td><td>&quot;COLOMBIA&quot;</td></tr><tr><td>&quot;2019-04-01 00:00:00&quot;</td><td>&quot;2019&quot;</td><td>&quot;04&quot;</td><td>&quot;AAL&quot;</td><td>&quot;AMERICAN&quot;</td><td>&quot;AMS&quot;</td><td>&quot;CTG&quot;</td><td>&quot;SCHIPHOL&quot;</td><td>&quot;CARTAGENA - RAFAEL NUQEZ&quot;</td><td>&quot;2&quot;</td><td>&quot;I&quot;</td><td>&quot;R&quot;</td><td>&quot;AMSTERDAM&quot;</td><td>&quot;CARTAGENA&quot;</td><td>&quot;HOLANDA&quot;</td><td>&quot;COLOMBIA&quot;</td></tr><tr><td>&quot;2019-04-01 00:00:00&quot;</td><td>&quot;2019&quot;</td><td>&quot;04&quot;</td><td>&quot;AAL&quot;</td><td>&quot;AMERICAN&quot;</td><td>&quot;ANU&quot;</td><td>&quot;MDE&quot;</td><td>&quot;ANTIGUA LEEWARDS V.C.BIRD,&quot;</td><td>&quot;RIONEGRO - JOSE M. CORDOVA&quot;</td><td>&quot;1&quot;</td><td>&quot;I&quot;</td><td>&quot;R&quot;</td><td>&quot;ST. JOHN&#x27;S&quot;</td><td>&quot;RIONEGRO - ANTIOQUIA&quot;</td><td>&quot;ANTIGUA AND BARBUDA&quot;</td><td>&quot;COLOMBIA&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2019-May&quot;</td><td>&quot;2019&quot;</td><td>&quot;5&quot;</td><td>&quot;WGN&quot;</td><td>&quot;WESTERN GLOBAL&quot;</td><td>&quot;BOG&quot;</td><td>&quot;MIA&quot;</td><td>&quot;BOGOTA - ELDORADO&quot;</td><td>&quot;MIAMI INTL&quot;</td><td>&quot;0&quot;</td><td>&quot;I&quot;</td><td>&quot;C&quot;</td><td>&quot;BOGOTA&quot;</td><td>&quot;MIAMI&quot;</td><td>&quot;COLOMBIA&quot;</td><td>&quot;ESTADOS UNIDOS&quot;</td></tr><tr><td>&quot;2019-May&quot;</td><td>&quot;2019&quot;</td><td>&quot;5&quot;</td><td>&quot;WGN&quot;</td><td>&quot;WESTERN GLOBAL&quot;</td><td>&quot;DFW&quot;</td><td>&quot;BOG&quot;</td><td>&quot;DALLAS&quot;</td><td>&quot;BOGOTA - ELDORADO&quot;</td><td>&quot;0&quot;</td><td>&quot;I&quot;</td><td>&quot;C&quot;</td><td>&quot;DALAS&quot;</td><td>&quot;BOGOTA&quot;</td><td>&quot;ESTADOS UNIDOS&quot;</td><td>&quot;COLOMBIA&quot;</td></tr><tr><td>&quot;2019-May&quot;</td><td>&quot;2019&quot;</td><td>&quot;5&quot;</td><td>&quot;WGN&quot;</td><td>&quot;WESTERN GLOBAL&quot;</td><td>&quot;MDE&quot;</td><td>&quot;MIA&quot;</td><td>&quot;RIONEGRO - JOSE M. CORDOVA&quot;</td><td>&quot;MIAMI INTL&quot;</td><td>&quot;0&quot;</td><td>&quot;I&quot;</td><td>&quot;C&quot;</td><td>&quot;RIONEGRO - ANTIOQUIA&quot;</td><td>&quot;MIAMI&quot;</td><td>&quot;COLOMBIA&quot;</td><td>&quot;ESTADOS UNIDOS&quot;</td></tr><tr><td>&quot;2019-May&quot;</td><td>&quot;2019&quot;</td><td>&quot;5&quot;</td><td>&quot;WGN&quot;</td><td>&quot;WESTERN GLOBAL&quot;</td><td>&quot;MIA&quot;</td><td>&quot;BOG&quot;</td><td>&quot;MIAMI INTL&quot;</td><td>&quot;BOGOTA - ELDORADO&quot;</td><td>&quot;0&quot;</td><td>&quot;I&quot;</td><td>&quot;C&quot;</td><td>&quot;MIAMI&quot;</td><td>&quot;BOGOTA&quot;</td><td>&quot;ESTADOS UNIDOS&quot;</td><td>&quot;COLOMBIA&quot;</td></tr><tr><td>&quot;2019-May&quot;</td><td>&quot;2019&quot;</td><td>&quot;5&quot;</td><td>&quot;WGN&quot;</td><td>&quot;WESTERN GLOBAL&quot;</td><td>&quot;MIA&quot;</td><td>&quot;MDE&quot;</td><td>&quot;MIAMI INTL&quot;</td><td>&quot;RIONEGRO - JOSE M. CORDOVA&quot;</td><td>&quot;0&quot;</td><td>&quot;I&quot;</td><td>&quot;C&quot;</td><td>&quot;MIAMI&quot;</td><td>&quot;RIONEGRO - ANTIOQUIA&quot;</td><td>&quot;ESTADOS UNIDOS&quot;</td><td>&quot;COLOMBIA&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (556_413, 16)\n",
       "┌───────────────┬──────┬─────┬─────────┬───┬──────────────┬──────────────┬──────────────┬──────────┐\n",
       "│ Fecha         ┆ Año  ┆ Mes ┆ Sigla   ┆ … ┆ Ciudad       ┆ Ciudad       ┆ Pais Origen  ┆ Pais     │\n",
       "│ ---           ┆ ---  ┆ --- ┆ Empresa ┆   ┆ Origen       ┆ Destino      ┆ ---          ┆ Destino  │\n",
       "│ str           ┆ str  ┆ str ┆ ---     ┆   ┆ ---          ┆ ---          ┆ str          ┆ ---      │\n",
       "│               ┆      ┆     ┆ str     ┆   ┆ str          ┆ str          ┆              ┆ str      │\n",
       "╞═══════════════╪══════╪═════╪═════════╪═══╪══════════════╪══════════════╪══════════════╪══════════╡\n",
       "│ 2019-04-01    ┆ 2019 ┆ 04  ┆ AAL     ┆ … ┆ TEXAS        ┆ BOGOTA       ┆ ESTADOS      ┆ COLOMBIA │\n",
       "│ 00:00:00      ┆      ┆     ┆         ┆   ┆              ┆              ┆ UNIDOS       ┆          │\n",
       "│ 2019-04-01    ┆ 2019 ┆ 04  ┆ AAL     ┆ … ┆ NUEVO MEXICO ┆ BOGOTA       ┆ ESTADOS      ┆ COLOMBIA │\n",
       "│ 00:00:00      ┆      ┆     ┆         ┆   ┆              ┆              ┆ UNIDOS       ┆          │\n",
       "│ 2019-04-01    ┆ 2019 ┆ 04  ┆ AAL     ┆ … ┆ ABENDEEN     ┆ CALI         ┆ INGLATERRA   ┆ COLOMBIA │\n",
       "│ 00:00:00      ┆      ┆     ┆         ┆   ┆              ┆              ┆              ┆          │\n",
       "│ 2019-04-01    ┆ 2019 ┆ 04  ┆ AAL     ┆ … ┆ AMSTERDAM    ┆ CARTAGENA    ┆ HOLANDA      ┆ COLOMBIA │\n",
       "│ 00:00:00      ┆      ┆     ┆         ┆   ┆              ┆              ┆              ┆          │\n",
       "│ 2019-04-01    ┆ 2019 ┆ 04  ┆ AAL     ┆ … ┆ ST. JOHN'S   ┆ RIONEGRO -   ┆ ANTIGUA AND  ┆ COLOMBIA │\n",
       "│ 00:00:00      ┆      ┆     ┆         ┆   ┆              ┆ ANTIOQUIA    ┆ BARBUDA      ┆          │\n",
       "│ …             ┆ …    ┆ …   ┆ …       ┆ … ┆ …            ┆ …            ┆ …            ┆ …        │\n",
       "│ 2019-May      ┆ 2019 ┆ 5   ┆ WGN     ┆ … ┆ BOGOTA       ┆ MIAMI        ┆ COLOMBIA     ┆ ESTADOS  │\n",
       "│               ┆      ┆     ┆         ┆   ┆              ┆              ┆              ┆ UNIDOS   │\n",
       "│ 2019-May      ┆ 2019 ┆ 5   ┆ WGN     ┆ … ┆ DALAS        ┆ BOGOTA       ┆ ESTADOS      ┆ COLOMBIA │\n",
       "│               ┆      ┆     ┆         ┆   ┆              ┆              ┆ UNIDOS       ┆          │\n",
       "│ 2019-May      ┆ 2019 ┆ 5   ┆ WGN     ┆ … ┆ RIONEGRO -   ┆ MIAMI        ┆ COLOMBIA     ┆ ESTADOS  │\n",
       "│               ┆      ┆     ┆         ┆   ┆ ANTIOQUIA    ┆              ┆              ┆ UNIDOS   │\n",
       "│ 2019-May      ┆ 2019 ┆ 5   ┆ WGN     ┆ … ┆ MIAMI        ┆ BOGOTA       ┆ ESTADOS      ┆ COLOMBIA │\n",
       "│               ┆      ┆     ┆         ┆   ┆              ┆              ┆ UNIDOS       ┆          │\n",
       "│ 2019-May      ┆ 2019 ┆ 5   ┆ WGN     ┆ … ┆ MIAMI        ┆ RIONEGRO -   ┆ ESTADOS      ┆ COLOMBIA │\n",
       "│               ┆      ┆     ┆         ┆   ┆              ┆ ANTIOQUIA    ┆ UNIDOS       ┆          │\n",
       "└───────────────┴──────┴─────┴─────────┴───┴──────────────┴──────────────┴──────────────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(schema=\n",
    "             {'Fecha':pl.Utf8,\"Año\":pl.Utf8,\"Mes\":pl.Utf8,'Sigla Empresa':pl.Utf8,'Nombre Empresa':pl.Utf8,\n",
    "              'Origen':pl.Utf8, 'Destino':pl.Utf8, 'Apto_Origen':pl.Utf8,'Apto_Destino':pl.Utf8,\n",
    "              'Pasajeros':pl.Utf8, 'Trafico':pl.Utf8,'TipoVuelo':pl.Utf8, 'Ciudad Origen':pl.Utf8, 'Ciudad Destino':pl.Utf8,\n",
    "              'Pais Origen':pl.Utf8, 'Pais Destino':pl.Utf8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(unique_schemas.values())[0]\n",
    "filename  = a[0]\n",
    "file_path = os.path.join(directory, filename)\n",
    "columns = read_excel_header(file_path)\n",
    "num_columns = len(columns)\n",
    "skip_r=1\n",
    "\n",
    "num_columns\n",
    "\n",
    "while num_columns <3:\n",
    "    columns = read_excel_header(file_path, skip=skip_r)\n",
    "    num_columns = len(columns)\n",
    "    skip_r+=1\n",
    "columns\n",
    "\n",
    "pd.read_excel(file_path, skiprows=skip_r-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(schema=\n",
    "             {'Fecha':pl.Utf8,\"Año\":pl.Utf8,\"Mes\":pl.Utf8,'Sigla Empresa':pl.Utf8,'Nombre Empresa':pl.Utf8,\n",
    "              'Origen':pl.Utf8, 'Destino':pl.Utf8, 'Apto_Origen':pl.Utf8,'Apto_Destino':pl.Utf8,\n",
    "              'Pasajeros':pl.Utf8, 'Trafico':pl.Utf8,'TipoVuelo':pl.Utf8, 'Ciudad Origen':pl.Utf8, 'Ciudad Destino':pl.Utf8,\n",
    "              'Pais Origen':pl.Utf8, 'Pais Destino':pl.Utf8})\n",
    "\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.xlsx'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                columns = read_excel_header(file_path)\n",
    "                num_columns = len(columns)\n",
    "                skip_r=1\n",
    "                while num_columns <3:\n",
    "                    columns = read_excel_header(file_path, skip=skip_r)\n",
    "                    num_columns = len(columns)\n",
    "                    skip_r+=1\n",
    "                tmp = pd.read_excel(file_path, skiprows=skip_r-1, dtype=\"str\")\n",
    "                if filename in list(unique_schemas.values())[0]:\n",
    "                     tmp[\"Año\"] = \"\"\n",
    "                     tmp[\"Mes\"] = \"\"\n",
    "                     tmp = tmp[['Fecha',\"Año\",\"Mes\",'Sigla Empresa','Nombre Empresa',\n",
    "                                  'Origen', 'Destino', 'Apto_Origen','Apto_Destino',\n",
    "                                'Pasajeros', 'Trafico','TipoVuelo', 'Ciudad Origen', 'Ciudad Destino',\n",
    "                                'Pais Origen', 'Pais Destino']]\n",
    "                     tmp = pl.DataFrame(tmp)\n",
    "                     tmp = tmp.with_columns(pl.col(\"Fecha\").str.to_datetime().dt.year().alias(\"Año\").cast(pl.Utf8),\n",
    "                                     pl.col(\"Fecha\").str.to_datetime().dt.month().alias(\"Mes\").cast(pl.Utf8))\n",
    "                     df = pl.concat([df,tmp])\n",
    "                else:\n",
    "                     continue            \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to open file {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file = list(unique_schemas.values())[0][1]\n",
    "file_path = os.path.join(directory, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_excel(file_path, skiprows=skip_r, dtype=\"str\")\n",
    "tmp[\"Año\"] = \"\"\n",
    "tmp[\"Mes\"] = \"\"\n",
    "tmp = tmp[['Fecha',\"Año\",\"Mes\",'Sigla Empresa','Nombre Empresa',\n",
    "                                  'Origen', 'Destino', 'Apto_Origen','Apto_Destino',\n",
    "                                'Pasajeros', 'Trafico','TipoVuelo', 'Ciudad Origen', 'Ciudad Destino',\n",
    "                                'Pais Origen', 'Pais Destino']]\n",
    "tmp = pl.DataFrame(tmp)\n",
    "\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.with_columns(pl.col(\"Fecha\").str.to_datetime().dt.year().alias(\"Año\").cast(pl.Utf8),\n",
    "                                     pl.col(\"Fecha\").str.to_datetime().dt.month().alias(\"Mes\").cast(pl.Utf8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_schemas[\"schema 1\"] == dict_schemas[\"schema 1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = list(unique_schemas.keys())\n",
    "len(schemas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pd.Series(schemas[0]).sort_values().reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(schemas[1]).sort_values().reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harmonizar\n",
    "CargaKg Carga (Kg) | CorreoKg Correo (Kg) | Nombre Empresa Nombre | Tipo Vuelo TipoVuelo |Trafico Tráfico (N/I)\n",
    "#agreegar a todos\n",
    "Año  Número de Mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(schemas[2]).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(schemas[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
